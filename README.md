# Test Automation Best Practices in Action

[![Coverage Status](https://coveralls.io/repos/github/jpourdanis/playwright-test-coverage/badge.svg?branch=main)](https://coveralls.io/github/jpourdanis/playwright-test-coverage?branch=main)
[![CI](https://github.com/jpourdanis/playwright-test-coverage/actions/workflows/nodejs.yml/badge.svg)](https://github.com/jpourdanis/playwright-test-coverage/actions/workflows/nodejs.yml)

![Demo Animation](demo.webp)

A comprehensive reference project demonstrating **senior-level QA engineering best practices** using [Playwright](https://playwright.dev). This repository goes beyond simple end-to-end tests to showcase the patterns, architectures, and strategies that make a test suite **robust, maintainable, and scalable**.

## Table of Contents

- [Best Practices Implemented](#best-practices-implemented)
  - [1. Page Object Model (POM)](#1-page-object-model-pom)
  - [2. Accessibility (a11y) Testing](#2-accessibility-a11y-testing)
    - [Handling i18n with Accessibility Locators](#handling-i18n-with-accessibility-locators)
  - [3. Network Mocking & Interception](#3-network-mocking--interception)
  - [4. Visual Regression & Responsive Testing](#4-visual-regression--responsive-testing)
  - [5. Data-Driven Testing](#5-data-driven-testing)
  - [6. E2E Code Coverage](#6-e2e-code-coverage)
  - [7. Consistent Cross-Platform Testing with Docker](#7-consistent-cross-platform-testing-with-docker)
  - [8. Allure Reports with Historical Data & Flaky Test Detection](#8-allure-reports-with-historical-data--flaky-test-detection)
  - [9. Cross-Browser Testing Strategy](#9-cross-browser-testing-strategy)
  - [10. Behavior-Driven Development (BDD) with Cucumber](#10-behavior-driven-development-bdd-with-cucumber)
- [Getting Started](#getting-started)

---

## Best Practices Implemented

### 1. Page Object Model (POM)

**Files:** [`e2e/pages/HomePage.ts`](/e2e/pages/HomePage.ts) Â· [`e2e/tests/pom-refactored.spec.ts`](/e2e/tests/pom-refactored.spec.ts)

#### What is it?

The Page Object Model is a design pattern that creates an abstraction layer between your tests and the page structure. Instead of scattering selectors like `page.locator("header")` across dozens of test files, you define them **once** inside a dedicated class.

#### Why it matters

- **Maintainability** â€” When a selector changes (e.g., a button class is renamed), you update it in **one place** instead of every test file that references it.
- **Readability** â€” Tests read like user stories: `homePage.clickColorButton("Red")` is instantly understandable, even by non-engineers.
- **Reusability** â€” The same page object is shared across multiple test suites, eliminating duplicated boilerplate.

#### How to implement

**Step 1:** Create a page class with locators and actions:

```typescript
// e2e/pages/HomePage.ts
import { Page, Locator } from "@playwright/test";

export class HomePage {
  readonly page: Page;
  readonly header: Locator;
  readonly currentColorText: Locator;

  constructor(page: Page) {
    this.page = page;
    this.header = page.locator("header");
    this.currentColorText = page.locator("text=Current color:");
  }

  async goto() {
    await this.page.goto("/");
  }

  async clickColorButton(colorName: string) {
    await this.page.click(`text=${colorName}`);
  }
}
```

**Step 2:** Use the page object in your tests:

```typescript
// e2e/tests/pom-refactored.spec.ts
test.describe("POM Refactored: Background color tests", () => {
  let homePage: HomePage;

  test.beforeEach(async ({ page }) => {
    homePage = new HomePage(page);
    await homePage.goto();
  });

  test("verify Red is applied as the background color", async () => {
    await homePage.clickColorButton("Red");
    const text = await homePage.getCurrentColorText();
    // ... assertions
  });
});
```

#### How to verify

```bash
npx playwright test e2e/tests/pom-refactored.spec.ts
```

---

### 2. Accessibility (a11y) Testing

**File:** [`e2e/tests/a11y.spec.ts`](/e2e/tests/a11y.spec.ts)

#### What is it?

Automated accessibility auditing that scans your rendered DOM against the [Web Content Accessibility Guidelines (WCAG)](https://www.w3.org/WAI/standards-guidelines/wcag/). We use [`@axe-core/playwright`](https://github.com/dequelabs/axe-core-npm/tree/develop/packages/playwright) â€” the same engine used by browser DevTools accessibility audits.

#### Why it matters

- **Inclusivity** â€” Ensures the application is usable by individuals with visual, motor, or cognitive disabilities.
- **Legal compliance** â€” Many jurisdictions require WCAG AA compliance for public-facing web applications.
- **Regression prevention** â€” A CSS refactor can silently break color contrast ratios. An automated a11y gate catches it before merge.
- **Real bugs found** â€” In this project, the a11y tests uncovered actual contrast violations (white text on yellow/turquoise backgrounds) and missing semantic landmarks (`<main>`, `<h1>`) that were subsequently fixed.

#### How to implement

**Step 1:** Install the dependency:

```bash
npm install -D @axe-core/playwright
```

**Step 2:** Write a test that scans the page:

```typescript
// e2e/tests/a11y.spec.ts
import AxeBuilder from "@axe-core/playwright";

test("should not have any accessibility issues", async ({ page }) => {
  await page.goto("/");
  const results = await new AxeBuilder({ page }).analyze();
  expect(results.violations).toEqual([]);
});
```

**Step 3:** Test accessibility **after state changes** too â€” a button click that changes the background color could introduce new contrast violations:

```typescript
test("should maintain accessibility after color change", async ({ page }) => {
  await homePage.clickColorButton("Yellow");
  const results = await new AxeBuilder({ page }).analyze();
  const contrastViolations = results.violations.filter(
    (v) => v.id === "color-contrast"
  );
  expect(contrastViolations).toEqual([]);
});
```

#### How to verify

```bash
npx playwright test e2e/tests/a11y.spec.ts
```

If a violation is found, the output will include the exact rule ID (e.g., `color-contrast`), the failing HTML element, and the specific contrast ratio that failed.

#### Handling i18n with Accessibility Locators

**File:** [`e2e/tests/a11y.spec.ts`](/e2e/tests/a11y.spec.ts)

When an application has different languages, most engineers panic because their trusted English text locators would break once they change the testing language. 

So they abandon accessibility locators and fallback to the dark ages of DOM manipulation. They start writing locators like this:

ðŸš© `page.locator('.form-group .btn.btn-primary .submit-btn')`  
ðŸš© `page.locator('//div[@class="login-container"]/div[2]/form/button')`

This is how flaky pipelines are born, and the confidence in the testing is ruined. A developer adds one extra wrapper `div` for a layout tweak, and your entire test suite breaks.

There is a much cleaner way to handle this in Playwright. Your testing framework just needs a single source of truth. Keep it simple: load the correct language JSON file at runtime (e.g., using an environment variable, test parameters, or straight imports). Then you just pass that dynamic dictionary right back into your resilient Playwright locators:

```typescript
// Example: locating a button dynamically based on the current testing language
await page.getByRole('button', { name: i18nConfig.colors.red }).click();
```

Playwright inserts the correct string automatically. English, French, Spanish, or whatsoever â€” it does not matter. You keep the user-centric accessibility locators and ditch the brittle DOM paths. 

Do not compromise your architecture just because the text changes. Smart systems adapt to the context. Adding an additional language to the framework is done under a minute.

---

### 3. Network Mocking & Interception

**File:** [`e2e/tests/network-mocking.spec.ts`](/e2e/tests/network-mocking.spec.ts)

#### What is it?

Playwright's `page.route()` API allows you to intercept any network request and either **abort** it (simulating a failure) or **fulfill** it with custom data (mocking an API response).

#### Why it matters

- **Test isolation** â€” Tests don't depend on live APIs, databases, or third-party services. They run fast and never flake due to network issues.
- **Edge case coverage** â€” You can simulate states that are difficult to reproduce naturally: API errors, empty responses, rate limits, or missing assets.
- **Speed** â€” Mocked responses return instantly, dramatically reducing test execution time for API-heavy applications.

#### How to implement

**Aborting a request** (simulating a missing asset):

```typescript
test("should handle missing image gracefully", async ({ page }) => {
  // Intercept and abort the logo request BEFORE navigating
  await page.route("**/logo.svg", (route) => route.abort());
  await page.goto("/");

  // The image element should still exist in the DOM with its alt text
  const logoImg = page.locator("img.App-logo");
  await expect(logoImg).toHaveAttribute("alt", "logo");
});
```

**Mocking an API response** (fulfilling with custom data):

```typescript
test("mock API response", async ({ page }) => {
  await page.route("**/api/config", async (route) => {
    await route.fulfill({
      status: 200,
      contentType: "application/json",
      body: JSON.stringify({ defaultColor: "Red" }),
    });
  });
  await page.goto("/");
  // Assert the UI reflects the mocked data
});
```

> **Important:** Always call `page.route()` *before* the action that triggers the network request (e.g., `page.goto()`).

#### How to verify

```bash
npx playwright test e2e/tests/network-mocking.spec.ts
```

---

### 4. Visual Regression & Responsive Testing

**File:** [`e2e/tests/visual.spec.ts`](/e2e/tests/visual.spec.ts)

This file combines two complementary testing practices into a single suite: **visual regression** (pixel-level screenshot comparison) and **responsive design** (mobile viewport verification).

#### 4a. Visual Regression

##### What is it?

Visual regression testing captures a full-page screenshot and compares it pixel-by-pixel against a previously approved baseline image. If there's a difference, the test fails and generates a visual diff highlighting exactly what changed.

##### Why it matters

- **Catches what functional tests miss** â€” A CSS change that shifts a button 5 pixels to the left won't break any functional assertion, but it will break a visual snapshot.
- **Ideal for static content** â€” Pages like FAQs, landing pages, or dashboards benefit enormously from visual testing because their layout is their primary "feature."
- **Confidence in refactors** â€” When refactoring CSS or updating components, visual tests confirm nothing changed unexpectedly.

##### How to implement

```typescript
test.describe("Visual Regression", () => {
  test("homepage should match snapshot", async ({ page }) => {
    await page.goto("/");
    await page.waitForSelector("header");

    const screenshot = await page.screenshot({ fullPage: true });
    expect(screenshot).toMatchSnapshot("home.png");
  });
});
```

> **Important:** Visual regression baselines should be generated inside Docker to avoid OS-specific rendering differences. See [Section 7: Consistent Cross-Platform Testing with Docker](#7-consistent-cross-platform-testing-with-docker).

#### 4b. Responsive / Viewport Testing

##### What is it?

Testing your application under specific viewport dimensions to simulate how it renders on mobile phones, tablets, or other non-desktop devices.

##### Why it matters

- **Mobile-first reality** â€” Over 50% of global web traffic comes from mobile devices. Buttons that overlap or text that overflows can make an app unusable on a phone.
- **Layout regression prevention** â€” A CSS change on desktop can inadvertently break the mobile layout. Viewport tests catch these regressions automatically.
- **Cross-device confidence** â€” You verify functional correctness (not just appearance) at constrained dimensions â€” buttons can still be clicked, text is still readable.

##### How to implement

```typescript
test.describe("Responsive Design Testing", () => {
  // Simulate an iPhone SE viewport
  test.use({ viewport: { width: 375, height: 667 } });

  test("should render correctly on mobile viewport", async ({ page }) => {
    await page.goto("/");

    // Verify all critical elements are visible
    await expect(page.locator("header")).toBeVisible();
    await expect(page.locator("text=Turquoise")).toBeVisible();
    await expect(page.locator("text=Red")).toBeVisible();
    await expect(page.locator("text=Yellow")).toBeVisible();

    // Verify interactions still work at this size
    await page.click("text=Yellow");
    const text = await page.locator("text=Current color:").textContent();
    expect(text).toContain("#f1c40f");
  });
});
```

#### How to verify

```bash
npx playwright test e2e/tests/visual.spec.ts
```

Use Playwright's UI mode (`npx playwright test --ui`) to visually inspect how the page renders at the constrained viewport.

---

### 5. Data-Driven Testing

**File:** [`e2e/tests/data-driven.spec.ts`](/e2e/tests/data-driven.spec.ts)

#### What is it?

A pattern where a single test template is executed multiple times with different input data. Instead of writing three nearly identical tests for three colors, you define the data once and generate the tests programmatically.

#### Why it matters

- **DRY (Don't Repeat Yourself)** â€” The test logic is written once. Adding a new test case means adding one line to the data array, not copying an entire test block.
- **Scalability** â€” When your application adds a fourth or fifth color, you add one object to the array and get full test coverage instantly.
- **Consistency** â€” Every data point goes through the exact same assertion pipeline, eliminating the risk of copy-paste bugs in duplicated test blocks.

#### How to implement

**Step 1:** Define the test dataset:

```typescript
const testData = [
  { name: "Turquoise", expectedHex: "#1abc9c", expectedRgb: "rgb(26, 188, 156)" },
  { name: "Red",       expectedHex: "#e74c3c", expectedRgb: "rgb(231, 76, 60)"  },
  { name: "Yellow",    expectedHex: "#f1c40f", expectedRgb: "rgb(241, 196, 15)"  },
];
```

**Step 2:** Loop over the data to generate tests:

```typescript
test.describe("Data-Driven Testing", () => {
  for (const data of testData) {
    test(`changing color to ${data.name} should reflect in UI and DOM`, async ({ page }) => {
      await homePage.clickColorButton(data.name);
      await expect(homePage.currentColorText).toContainText(data.expectedHex);
      await expect(homePage.header).toHaveCSS("background-color", data.expectedRgb);
    });
  }
});
```

#### How to verify

```bash
npx playwright test e2e/tests/data-driven.spec.ts
```

The output will list **three distinct test names** â€” one per dataset entry â€” confirming that a single test block generated multiple independent executions.

---

### 6. E2E Code Coverage

**Files:** [`e2e/baseFixtures.ts`](/e2e/baseFixtures.ts) Â· [`e2e/tests/coverage.spec.ts`](/e2e/tests/coverage.spec.ts)

#### What is it?

Code coverage measurement for **end-to-end tests**, not just unit tests. Using [Istanbul/nyc](https://github.com/istanbuljs/nyc), we instrument the application at build time and collect coverage data from the browser during Playwright test execution. This tells you exactly which lines, branches, and functions of your source code are exercised by your E2E suite.

#### Why it matters

- **Identifies blind spots** â€” Shows which parts of your codebase have no E2E test coverage, guiding you on where to write the next test.
- **Measures test effectiveness** â€” A test suite with 200 tests but 30% coverage has fundamental gaps. Coverage metrics make this visible.
- **CI/CD integration** â€” Coverage data is uploaded to [Coveralls](https://coveralls.io/) on every push, providing historical trends and PR-level deltas.
- **Stakeholder communication** â€” Coverage percentages are easy to understand and share with product managers and engineering leads.

#### How it works

The custom `baseFixtures.ts` extends Playwright's test runner to:

1. **Inject** a `beforeunload` listener that serializes Istanbul's `__coverage__` object
2. **Expose** a `collectIstanbulCoverage` function to the browser context
3. **Collect** coverage data from every open page after each test completes
4. **Write** coverage JSON files to `.nyc_output/` with unique UUIDs

#### How to implement

**Step 1:** Ensure your build pipeline includes `babel-plugin-istanbul` (controlled via the `USE_BABEL_PLUGIN_ISTANBUL` env var).

**Step 2:** Import from `baseFixtures` instead of `@playwright/test`:

```typescript
// e2e/tests/coverage.spec.ts
import { test, expect } from "../baseFixtures"; // â† NOT from @playwright/test
```

**Step 3:** Write your tests as usual â€” coverage collection is automatic.

#### Generating reports

```bash
# Run tests with coverage collection
npm run coverage

# Or generate reports manually:
npx nyc report --reporter=html    # HTML report â†’ coverage/index.html
npx nyc report --reporter=lcov    # For Coveralls / Codecov upload
npx nyc report --reporter=text    # CLI summary table
```

#### How to verify

```bash
npm run coverage
```

The CLI will output a table showing per-file statement, branch, function, and line coverage percentages.

---

### 7. Consistent Cross-Platform Testing with Docker

#### What is it?

A Docker-based testing environment that guarantees identical rendering and test behavior across all machines â€” developer laptops, CI servers, and staging environments.

#### Why it matters

Visual regression tests are particularly sensitive to cross-platform differences. A screenshot taken on **macOS** will differ from one taken on **Linux** due to subtle variations in:

- **Font rendering** â€” macOS uses Core Text, Linux uses FreeType â€” same font, different pixels
- **Anti-aliasing** â€” Sub-pixel smoothing algorithms differ between OSes
- **System fonts** â€” Default fallback fonts vary across platforms

These differences cause **false positives**: tests pass locally on macOS but fail in Linux-based CI, or vice versa. This erodes trust in the test suite and wastes debugging time.

#### The solution

We use Docker with the official [Playwright Docker image](https://hub.docker.com/_/microsoft-playwright) (`mcr.microsoft.com/playwright`) to lock the rendering environment. Our `docker-compose.yml` defines two services:

```
docker-compose.yml
â”œâ”€â”€ app service         â†’ Runs the React dev server on port 3000
â””â”€â”€ playwright service  â†’ Runs Playwright tests against the app
```

**Dockerfile** (simplified):

```dockerfile
FROM mcr.microsoft.com/playwright:v1

WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .

CMD ["npm", "test"]
```

**Key Docker Compose features:**

- **Consistent rendering** â€” The official Playwright image pins browser versions and system libraries
- **Volume mounts** â€” Snapshots (`e2e/snapshots/`) and test results (`test-results/`) persist between container runs, so updated baselines are always available on the host
- **CI-ready** â€” The same Docker configuration runs locally and in GitHub Actions

#### How to use

```bash
# Run the full test suite in Docker
npm run test:e2e:docker

# Update visual regression baselines (after intentional UI changes)
npm run test:e2e:docker:update
```

> **Tip:** Always review visual diffs before accepting updated baselines. Never blindly run `--update-snapshots`.

---

### 8. Allure Reports with Historical Data & Flaky Test Detection

ðŸ‘‰ **[View the Live Allure Report for this Repository](https://jpourdanis.github.io/test-automation-best-practices/)**

#### What is it?

[Allure Framework](https://allurereport.org/) is a flexible lightweight multi-language test report tool that not only shows a very concise representation of what has been tested in a neat web report form, but allows everyone participating in the development process to extract maximum useful information from everyday execution of tests. We've integrated `allure-playwright` to automatically generate these reports.

#### Why it matters

- **Historical Data** â€” Standard Playwright HTML reports are ephemeral; they overwrite on the next run. Allure maintains a history of test executions, allowing you to see trends over time (e.g., "this test has been failing for the last 5 builds").
- **Flaky Test Detection** â€” Because Allure tracks history, it can easily identify "flaky" testsâ€”tests that pass and fail intermittently without code changes. This is crucial for maintaining a trustworthy test suite.
- **Rich Visualizations** â€” Allure categorizes failures into Product Defects (bugs) and Test Defects (broken tests), providing a clear dashboard for stakeholders to understand the health of the application.
- **Attachments** â€” Screenshots (like visual regression diffs), videos, and traces collected by Playwright are natively embedded into the Allure report for easy debugging.

#### How to implement

**Step 1:** Install the necessary packages.

```bash
npm install -D allure-playwright
npm install -g allure-commandline # For viewing reports locally
```

**Step 2:** Configure Playwright to use the Allure reporter in `playwright.config.ts`.

```typescript
  reporter: process.env.CI
    ? [
        ["allure-playwright"],
        ["list"],
      ]
    : [
        ["html", { open: "never" }],
        ["allure-playwright"],
        ["list"],
      ],
```

**Step 3:** Use GitHub Actions to build and publish the report with historical data.

Our CI workflow uses `simple-elf/allure-report-action` to build the report. Crucially, it fetches the previous `allure-history` from the `gh-pages` branch, allowing Allure to compute trends. It then publishes the updated report back to GitHub Pages.

#### How to verify

To view the report locally after running tests:

```bash
npx allure serve allure-results
```

In CI, navigate to the repository's GitHub Pages URL after a build finishes to view the continually updated historical report.

---

### 9. Cross-Browser Testing Strategy

**File:** [`playwright.config.ts`](/playwright.config.ts) Â· [`e2e/tests/cross-browser.spec.ts`](/e2e/tests/cross-browser.spec.ts)

#### What is it?

A conditional strategy for running tests across multiple browser engines (Chromium, Firefox, and WebKit) without permanently inflating the CI execution time for every single commit.

#### Why it matters

Many teams configure Playwright to run every test on all three browsers. While this provides great coverage, it multiplies your test execution time by 3. If a PR takes 15 minutes to run UI tests on Chrome, it will take 45 minutes to run all three browsers. This destroys the developer feedback loop.

The senior QA best practice is **Conditional Execution**:
1. **Pull Requests / Local Dev:** Run tests fast on one primary engine (e.g., Chromium).
2. **Nightly / Release Branches:** Run full regression across all browsers using an environment variable flag.

#### How to implement

We configure our `playwright.config.ts` to dynamically inject browser projects based on an environment variable (`CROSS_BROWSER`):

```typescript
  projects: [
    {
      name: "Chrome",
      use: { ...devices["Desktop Chrome"] },
    },
    // Conditionally load other browsers only when requested
    ...(process.env.CROSS_BROWSER === "true"
      ? [
          { name: "Firefox", use: { ...devices["Desktop Firefox"] } },
          { name: "WebKit",  use: { ...devices["Desktop Safari"] } },
        ]
      : []),
  ],
```

#### How to verify

**Run fast on default browser (Chromium only):**
```bash
npm run test
```

**Run deep coverage across all engines (Chromium, Firefox, WebKit):**
```bash
npm run test:cross-browser
```

---

### 10. Behavior-Driven Development (BDD) with Cucumber

**Files:** [`e2e/features/home.feature`](/e2e/features/home.feature) Â· [`e2e/tests/bdd.spec.ts`](/e2e/tests/bdd.spec.ts)

#### What is it?

Behavior-Driven Development (BDD) closes the gap between business stakeholders and QA engineers by expressing tests in plain English using Gherkin syntax. We use [`playwright-bdd`](https://github.com/vitalets/playwright-bdd) to seamlessly compile `.feature` files into native Playwright tests.

#### Why it matters

- **Living Documentation** â€” Your test artifacts serve as the actual source of truth for product requirements.
- **Improved Collaboration** â€” Product Managers can review or even write the Gherkin scenarios without needing to understand TypeScript or Playwright APIs.
- **Reusability** â€” The step definitions (`bdd.spec.ts`) leverage the same Page Object Models used by standard end-to-end tests, maximizing reusability and reducing duplication.

#### How to implement

**Step 1:** Write a Gherkin feature file outlining the desired behavior:

```gherkin
# e2e/features/home.feature
Feature: Home Page Background Color

  Scenario Outline: Change background color
    Given I am on the home page
    When I click the "<color>" color button
    Then the background color should be "<rgb>"

    Examples:
      | color     | rgb                |
      | Turquoise | rgb(26, 188, 156)  |
```

**Step 2:** Write the Step Definitions using Playwright and your Page Objects:

```typescript
// e2e/tests/bdd.spec.ts
import { createBdd } from "playwright-bdd";
import { HomePage } from "../pages/HomePage";

const { Given, When, Then } = createBdd();
let homePage: HomePage;

Given("I am on the home page", async ({ page }) => {
  homePage = new HomePage(page);
  await homePage.goto();
});
// ... Map other steps
```

#### How to verify

Execute the BDD tests specifically:
```bash
npm run test:bdd
```

---

## Getting Started

### Prerequisites

- Node.js 16+
- Docker (for visual regression and consistent cross-platform tests)

### Installation

```bash
npm install
npx playwright install
```

### Running tests locally

```bash
# Run all e2e tests (starts dev server automatically)
npx playwright test

# Run a specific test suite
npx playwright test e2e/tests/a11y.spec.ts

# Run in headed mode (see the browser)
npx playwright test --headed

# Run in UI mode (interactive debugging)
npx playwright test --ui

# Run with coverage
npm run coverage

# Run BDD (Cucumber) tests
npm run test:bdd
```

### Project structure

```text
src/
â”œâ”€â”€ locales/
â”‚   â”œâ”€â”€ el.json                  # Greek translation file
â”‚   â”œâ”€â”€ en.json                  # English translation file (default)
â”‚   â””â”€â”€ es.json                  # Spanish translation file
e2e/
â”œâ”€â”€ features/
â”‚   â””â”€â”€ home.feature             # Gherkin BDD scenarios
â”œâ”€â”€ pages/
â”‚   â””â”€â”€ HomePage.ts              # Page Object Model
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ a11y.spec.ts             # Accessibility testing (with i18n support)
â”‚   â”œâ”€â”€ bdd.spec.ts              # Step definitions for BDD tests
â”‚   â”œâ”€â”€ coverage.spec.ts         # E2E tests with code coverage
â”‚   â”œâ”€â”€ cross-browser.spec.ts    # Cross-browser testing strategy
â”‚   â”œâ”€â”€ data-driven.spec.ts      # Data-driven testing
â”‚   â”œâ”€â”€ network-mocking.spec.ts  # Network mocking & interception
â”‚   â”œâ”€â”€ pom-refactored.spec.ts   # POM demonstration
â”‚   â””â”€â”€ visual.spec.ts           # Visual regression & responsive testing
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ home.png                 # Visual regression baseline
â”œâ”€â”€ baseFixtures.ts              # Istanbul coverage fixture
â””â”€â”€ helper.ts                    # Utility functions
```
